{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a4ceae4-8a17-45ac-83fa-3ac5da3f00c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97997667-3c9b-4c86-a4ee-7134de4cbb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40f1c218-5f32-4926-aa7c-8f309f9a63dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Duration Protocol Direction State  Source_Type_of_Service  \\\n",
      "0  1.026539      tcp        ->  S_RA                     0.0   \n",
      "1  1.009595      tcp        ->  S_RA                     0.0   \n",
      "2  3.056586      tcp        ->  SR_A                     0.0   \n",
      "3  3.111769      tcp        ->  SR_A                     0.0   \n",
      "4  3.083411      tcp        ->  SR_A                     0.0   \n",
      "\n",
      "   Destination_Type_of_Service  Total_Packets  Total_Bytes  Source_Bytes  \\\n",
      "0                          0.0              4          276           156   \n",
      "1                          0.0              4          276           156   \n",
      "2                          0.0              3          182           122   \n",
      "3                          0.0              3          182           122   \n",
      "4                          0.0              3          182           122   \n",
      "\n",
      "                                    Label  \n",
      "0  flow=Background-Established-cmpgw-CVUT  \n",
      "1  flow=Background-Established-cmpgw-CVUT  \n",
      "2             flow=Background-TCP-Attempt  \n",
      "3             flow=Background-TCP-Attempt  \n",
      "4             flow=Background-TCP-Attempt  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/modified_utc_dataset.csv')\n",
    "\n",
    "# Initial data exploration\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06b43ec2-22e0-43d2-b872-f8f24eeceeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace([np.inf, -np.inf], np.nan)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b1565-9fe3-4907-9073-8ae3fc9d2703",
   "metadata": {},
   "source": [
    "**Feature selection**\n",
    "- we have seen the correlation between 'Total_Packets' and 'Total_Bytes' is approximately one.\n",
    "- The 'label's purpose is to help us identify whether the observation is from a botnet or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "062236fc-6de7-41fa-97f9-5a1421417396",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Label', 'Total_Bytes']\n",
    "columns_to_drop = [col for col in columns_to_drop if col in data.columns]\n",
    "\n",
    "data['botnet'] = data['Label'].apply(lambda x: 1 if 'flow=From-Botnet' in x else 0)\n",
    "\n",
    "data = data.drop(columns_to_drop, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baafb1af-2c47-4780-95c9-d23c2ee4dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical features into numerical\n",
    "data['Protocol'] = data['Protocol'].astype('category').cat.codes\n",
    "data['Protocol'] = data['Protocol'].astype(np.int32)\n",
    "data['Direction'] = data['Direction'].astype('category').cat.codes\n",
    "data['Direction'] = data['Direction'].astype(np.int32)\n",
    "data['State'] = data['State'].astype('category').cat.codes\n",
    "data['State'] = data['State'].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d218b05-372f-47e3-8bc4-ad18e6d45cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('botnet', axis =1)\n",
    "y = data['botnet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e785be36-3596-4b15-9376-1f99f1ce70ce",
   "metadata": {},
   "source": [
    "## Feature importance \n",
    "**Some features doesn't even have a single observation representing the other class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "354d4a81-4902-4f18-a4d6-51c9b69005b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for zero variance features and remove them\n",
    "variance = X.var()\n",
    "zero_variance_features = variance[variance == 0].index\n",
    "if len(zero_variance_features) > 0:\n",
    "    X.drop(columns=zero_variance_features, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19224d58-be6a-4c65-b0f4-93d345076614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Duration': 0.0, 'Protocol': 5.052265651175802e-59, 'Direction': 0.0, 'State': 0.0, 'Source_Type_of_Service': 7.057826559746228e-25, 'Destination_Type_of_Service': 0.00019255073119190503, 'Total_Packets': 0.0, 'Source_Bytes': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Apply chi-squared test and create a dictionary that holds the p-value and the features.\n",
    "chi_scores, p_values = chi2(X, y)\n",
    "chi2_results = {feature: p_value for feature, p_value in zip(X.columns, p_values)}\n",
    "\n",
    "print(chi2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c08dd937-3cc5-4dc5-b74f-fa51988edc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the feature data (if necessary for the specific context)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3491d459-1a89-46f9-a037-d53c21548ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest...\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models and hyperparameters for GridSearchCV\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'LogisticRegression': LogisticRegression()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]},\n",
    "    'SVC': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "    'DecisionTree': {'max_depth': [None, 10, 20, 30]},\n",
    "    'LogisticRegression': {'C': [0.1, 1, 10], 'penalty': ['l2']}\n",
    "}\n",
    "\n",
    "# Dictionary to store model performance metrics\n",
    "model_metrics = {\n",
    "    'Model': [],\n",
    "    'Time Taken': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1-Score': []\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning and model evaluation\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    grid = GridSearchCV(model, params[model_name], cv=5, scoring='roc_auc')\n",
    "    grid.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    time_taken = end_time - start_time\n",
    "    print(f\"testing {model_name} finished.\")\n",
    "\n",
    "    # Store metrics in the dictionary\n",
    "    model_metrics['Model'].append(model_name)\n",
    "    model_metrics['Time Taken'].append(time_taken)\n",
    "    model_metrics['Accuracy'].append(accuracy)\n",
    "    model_metrics['Precision'].append(precision)\n",
    "    model_metrics['Recall'].append(recall)\n",
    "    model_metrics['F1-Score'].append(f1)\n",
    "\n",
    "    print(f\"{model_name} Performance:\")\n",
    "    print(f\"Time Taken: {time_taken:.2f} seconds\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "    print(f\"ROC-AUC: {roc_auc}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d')\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # Save the best model\n",
    "    joblib.dump(best_model, f'{model_name}_best_model.pkl')\n",
    "\n",
    "# Create a DataFrame from the model_metrics dictionary\n",
    "metrics_df = pd.DataFrame(model_metrics)\n",
    "\n",
    "# Plotting the metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "sns.barplot(x='Model', y='Time Taken', data=metrics_df, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Time Taken by Each Model')\n",
    "\n",
    "sns.barplot(x='Model', y='Accuracy', data=metrics_df, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Accuracy of Each Model')\n",
    "\n",
    "sns.barplot(x='Model', y='Precision', data=metrics_df, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Precision of Each Model')\n",
    "\n",
    "sns.barplot(x='Model', y='F1-Score', data=metrics_df, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('F1-Score of Each Model')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b460252-79bb-49b3-b698-491dfb09cd15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
